{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Gh3HkAaZOLRU",
    "outputId": "6a89c700-f2e0-498f-e778-7dd24be5b765"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3b29dee5-2e04-45a0-8978-6ceca9b20e0d\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-3b29dee5-2e04-45a0-8978-6ceca9b20e0d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving f_model.tar to f_model (1).tar\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "kMXzDSe1OUT7",
    "outputId": "3c5bba52-bb43-47a1-ee46-d5db06cd3792"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7d2c4908-9036-4bda-8f48-6951b0af0e2b\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-7d2c4908-9036-4bda-8f48-6951b0af0e2b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final_f.tar to final_f (1).tar\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NJ2c5hiuyKS"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "#from base_test import BaseT|est\n",
    "#import digits_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import data\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import os\n",
    "#from torchsummary import summary\n",
    "#from data import NormalizeRangeTanh, UnNormalizeRangeTanh - What the hell is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-DcA-1vNjGGk"
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pwwe0MZuu53S"
   },
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "\n",
    "    def __init__(self): # What to do with GPU?\n",
    "        super(generator,self).__init__()\n",
    "        #self.channels=channels\n",
    "        #self.gpu= True\n",
    "        self.use_gpu = True\n",
    "        self.network=nn.Sequential(\n",
    "                     nn.ConvTranspose2d(128 ,512,kernel_size=(4,4), stride=1, padding=0),\n",
    "                     nn.BatchNorm2d(512),\n",
    "                     nn.ReLU(inplace=True),\n",
    "                     nn.ConvTranspose2d(512,256,kernel_size=(4,4), stride=2, padding=1),\n",
    "                     nn.BatchNorm2d(256),\n",
    "                     nn.ReLU(inplace=True),\n",
    "                     nn.ConvTranspose2d(256,128,kernel_size=(4,4), stride=2, padding=1),\n",
    "                     nn.BatchNorm2d(128),\n",
    "                     nn.ReLU(inplace=True),\n",
    "                     nn.ConvTranspose2d(128,1,kernel_size=(4,4), stride=2, padding=1),\n",
    "                     nn.Tanh()\n",
    "        )\n",
    "        if self.use_gpu:        \n",
    "                self.type(torch.cuda.FloatTensor)\n",
    "    def forward(self,input):\n",
    "        return self.network(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "5mJ9aFzxP13C",
    "outputId": "dc54e8c1-e91a-43da-c0f2-1d84d339cd61"
   },
   "outputs": [],
   "source": [
    "GEN = generator()\n",
    "#summary(GEN, (128, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1T6YDsRIxSP4"
   },
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "  \n",
    "    def __init__(self, leaky_coef=0.2):\n",
    "        super(discriminator, self).__init__()\n",
    "        #self.channels=channels\n",
    "        self.use_gpu = True\n",
    "\n",
    "        self.leaky_coef=leaky_coef\n",
    "        self.network=nn.Sequential(\n",
    "                     nn.Conv2d(1,128,kernel_size=(3,3), stride=2, padding=1),\n",
    "                     nn.BatchNorm2d(128),\n",
    "                     nn.LeakyReLU(self.leaky_coef,inplace=True),\n",
    "                     nn.Conv2d(128,256,kernel_size=(3,3), stride=2, padding=1),\n",
    "                     nn.BatchNorm2d(256),\n",
    "                     nn.LeakyReLU(self.leaky_coef,inplace=True),\n",
    "                     nn.Conv2d(256,512,kernel_size=(3,3), stride=2, padding=1),\n",
    "                     nn.BatchNorm2d(512),\n",
    "                     nn.LeakyReLU(self.leaky_coef,inplace=True),\n",
    "                     nn.Conv2d(512,3, kernel_size=(4,4), stride=2)\n",
    "        )\n",
    "        if self.use_gpu:        \n",
    "            self.type(torch.cuda.FloatTensor)\n",
    "\n",
    "            \n",
    "\n",
    "    def forward(self,input):\n",
    "        return self.network(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "oo8dvvsMjGGu",
    "outputId": "6f250f63-f63b-4d8b-decf-59ebf3bec49c"
   },
   "outputs": [],
   "source": [
    "DIS = discriminator()\n",
    "#summary(DIS, (1,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxatV29Sx5W9"
   },
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = args\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(self.shape)\n",
    "\n",
    "class feature_encoder(nn.Module):\n",
    "    def __init__(self, channels,gpu=True):\n",
    "        super(feature_encoder, self).__init__()\n",
    "        self.gpu = gpu\n",
    "        self.channels = channels\n",
    "        self.classify = nn.Sequential(\n",
    "                       nn.Conv2d(self.channels, 64, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.MaxPool2d(2),               \n",
    "                    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.Conv2d(256, 128, kernel_size=4, padding=0))\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#                     nn.MaxPool2d(4),\n",
    "#                     Reshape(-1,128),\n",
    "#                     nn.Linear(128, 10), \n",
    "#                     nn.Softmax(),)\n",
    "        if self.gpu:\n",
    "            self.type(torch.cuda.FloatTensor)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.classify(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "PaNhBHiOjGGz",
    "outputId": "bc54a9b0-53dd-4364-9be5-cd0771da1951"
   },
   "outputs": [],
   "source": [
    "FEA = feature_encoder(channels=3)\n",
    "#summary(FEA, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9aW0DY2zRLW"
   },
   "outputs": [],
   "source": [
    "# def classifier(address):\n",
    "#    # Kagi will guide us\n",
    "#   pass\n",
    "\n",
    "class tanh_normalize(object):\n",
    "    ''' Normalizes a tensor with values from [0, 1] to [-1, 1]. '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        sample = sample * 2.0 - 1.0\n",
    "        return sample\n",
    "\n",
    "class digits_transfer():\n",
    "  \n",
    "  \n",
    "    def __init__(self,gpu=True):\n",
    "    \n",
    "        super(digits_transfer,self).__init__()\n",
    "        self.gpu = gpu\n",
    "        self.generator_loss_function=None\n",
    "        self.gan_loss_function=None\n",
    "        self.discriminator_loss_function=None\n",
    "        #self.source_validation_loader=None\n",
    "        self.source_test_loader=None\n",
    "        self.target_test_loader=None\n",
    "        self.distance_target_domain=None\n",
    "        self.source_train_loader=None\n",
    "        self.target_train_loader=None\n",
    "        self.batch_size=128\n",
    "        self.lossCrossEntropy=nn.CrossEntropyLoss() ## Why the fuck is it here?\n",
    "    \n",
    "    def readClassifier(self, model_name):\n",
    "\n",
    "    #     old_model = torch.load(model_name)['state_dict']\n",
    "    #     old_dict = old_model.load_state_dict() \n",
    "    #     new_model = feature_encoder(3,self.gpu)\n",
    "    #     new_dict = new_model.state_dict()\n",
    "    #     new_dict = {k: v for k, v in old_dict.items() if k in new_dict}\n",
    "    #     old_dict.update(new_dict) \n",
    "    #     new_model.load_state_dict(new_dict)\n",
    "\n",
    "    #     model = describe_model()\n",
    "    #     checkpoint = torch.load('checkpoint.pth.tar')\n",
    "    #     model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        model = feature_encoder(channels = 3)\n",
    "        temp = torch.load(model_name)\n",
    "        model.load_state_dict(temp['state_dict'])\n",
    "        self.model['f'] =model\n",
    "\n",
    "        for param in self.model['f'].parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def data_loader(self):\n",
    "\n",
    "        SVHN = transforms.Compose([transforms.ToTensor(), tanh_normalize()])\n",
    "        MNIST = transforms.Compose([transforms.Scale(32), transforms.ToTensor(), tanh_normalize()])\n",
    "\n",
    "        source_train_set = torchvision.datasets.SVHN(root='./SVHN/', split='extra', download=True, transform=SVHN)\n",
    "        self.source_train_loader = torch.utils.data.DataLoader(source_train_set, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "        source_test_set = torchvision.datasets.SVHN(root='./SVHN/', split='test', download=True, transform=SVHN)\n",
    "        self.source_test_loader = torch.utils.data.DataLoader(source_test_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "        target_train_set = torchvision.datasets.MNIST(root='./MNIST/', train=True, download=True, transform=MNIST)\n",
    "        self.target_train_loader = torch.utils.data.DataLoader(target_train_set, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "        target_test_set = torchvision.datasets.MNIST(root='./MNIST/', train=False, download=True, transform=MNIST)\n",
    "        self.target_test_loader = torch.utils.data.DataLoader(target_test_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "    def view_batch(self):\n",
    "    ## TO be filled in later\n",
    "        pass\n",
    "  \n",
    "    def make_model(self):\n",
    "\n",
    "        self.model = {}\n",
    "        self.model['d'] = discriminator()\n",
    "        self.model['g'] = generator()\n",
    "        if self.gpu:\n",
    "          self.model['d'] = self.model['d'].cuda()\n",
    "          self.model['g'] = self.model['g'].cuda()\n",
    "        # Assumption 1 : Kagi saves everything as a Tar File\n",
    "        #self.model['f'] = classifier('Give the saved model here')\n",
    "        self.readClassifier('final_f.tar')\n",
    "\n",
    "    def create_discriminator_loss_function(self):\n",
    "\n",
    "        def discriminator_loss(s_d_g, t_d_g, t_d):  \n",
    "            return self.lossCrossEntropy(s_d_g.squeeze(), self.label_0)\n",
    "        #+ self.lossCrossEntropy(t_d_g, self.label_1) + self.lossCrossEntropy(t_d, self.label_2)\n",
    "\n",
    "        self.discriminator_loss_function = discriminator_loss\n",
    "  \n",
    "    def create_generator_loss_function(self):\n",
    "\n",
    "        def generator_loss(s_f, s_g_f, s_d_g, t , t_g, t_d_g, alpha = 0.1, beta = 15, gamma = 0):\n",
    "\n",
    "            loss_gan_generator = self.lossCrossEntropy(s_d_g.squeeze(), self.label_2)\n",
    "#              + self.lossCrossEntropy(t_d_g, self.label_2)\n",
    "            loss_feature_constancy = self.mean_square_loss(s_g_f, s_f.detach())\n",
    "            loss_target_identity = self.mean_square_loss(t_g, t.detach())\n",
    "\n",
    "            return loss_gan_generator + alpha*loss_feature_constancy + beta*loss_target_identity\n",
    "\n",
    "        self.generator_loss_function = generator_loss\n",
    "  \n",
    "\n",
    "    def make_loss_function(self):\n",
    "        self.lossCrossEntropy = nn.CrossEntropyLoss().cuda()\n",
    "        self.mean_square_loss = nn.MSELoss().cuda()\n",
    "        label_0, label_1, label_2 = (torch.LongTensor(self.batch_size) for i in range(3))\n",
    "        label_0 = Variable(label_0.cuda())\n",
    "        label_1 = Variable(label_1.cuda())\n",
    "        label_2 = Variable(label_2.cuda())\n",
    "        label_0.data.resize_(self.batch_size).fill_(0)\n",
    "        label_1.data.resize_(self.batch_size).fill_(1)\n",
    "        label_2.data.resize_(self.batch_size).fill_(2)\n",
    "        self.label_0 = label_0\n",
    "        self.label_1 = label_1\n",
    "        self.label_2 = label_2\n",
    "\n",
    "    #     selfLL.create_distance_function_target_domain()\n",
    "        self.create_discriminator_loss_function()\n",
    "        self.create_generator_loss_function()\n",
    "  \n",
    "    def make_optimizer(self):\n",
    "    \n",
    "        generator_learning_rate = 0.001\n",
    "        generator_weight_decay = 0.000001     \n",
    "        self.generator_optimizer = optim.Adam(self.model['g'].parameters(), lr = generator_learning_rate, weight_decay = generator_weight_decay)\n",
    "\n",
    "        discriminator_learning_rate = 0.001\n",
    "        discriminator_weight_decay = 0.000001     \n",
    "        self.discriminator_optimizer = optim.Adam(self.model['d'].parameters(), lr = discriminator_learning_rate, weight_decay = discriminator_weight_decay)\n",
    "\n",
    "    #   def validate_model(self, **kwargs):\n",
    "\n",
    "    #     gan_loss_weight = kwargs.get(\"gan_loss_weight\",0.001)\n",
    "    #     validation_loss = 0\n",
    "    #     self.model['g'].eval()\n",
    "    #     samples = np.random.randint(0,len(source_validation_set),size = 5)\n",
    "    #     for i in samples:\n",
    "    # #       ## source_validation_set is a keyword argument!\n",
    "    # #       source_datLLLa = source_validation_set[i]\n",
    "    # #       source_generator_output = self.model['g'](source_data)\n",
    "    # #       source_classifier_output = self.model['f'](source_data)\n",
    "    # #       source_\n",
    "    # #     \"\"\"\n",
    "    # #       To be Done Later\n",
    "    # #     \"\"\"\n",
    "    # #     pass\n",
    "\n",
    "    def show_image():\n",
    "        pass\n",
    "        # Fuck this shit\n",
    "    def display_results(self, source_data, source_generator):\n",
    "        \"\"\"\n",
    "          To be done later\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def model_train(self, number_of_epochs, **kwargs):\n",
    "    \n",
    "        visualize_batch = kwargs.get(\"visualize_batch\",50)\n",
    "        save_batch = kwargs.get(\"save_batch\",200)\n",
    "        test_batch = kwargs.get(\"test_batch\",200)\n",
    "\n",
    "        SVHN_count=0\n",
    "        batch_count=0\n",
    "        discriminator_run_loss=0\n",
    "        generator_run_loss=0\n",
    "\n",
    "        l=min(len(self.source_train_loader),len(self.target_train_loader))\n",
    "\n",
    "        for epoch in range(number_of_epochs):\n",
    "\n",
    "            source_data_iter=iter(self.source_train_loader)\n",
    "            target_data_iter=iter(self.target_train_loader)\n",
    "\n",
    "            for i in range(l):\n",
    "\n",
    "                SVHN_count+=1\n",
    "                if SVHN_count>=len(self.source_train_loader):\n",
    "                    SVHN_count=0\n",
    "                    source_data_iter=iter(self.source_train_loader)\n",
    "\n",
    "                source_data, source_labels=source_data_iter.next()\n",
    "                target_data, target_labels=target_data_iter.next()\n",
    "\n",
    "                if self.batch_size != source_data.size(0) or self.batch_size != target_data.size(0):\n",
    "                    continue\n",
    "\n",
    "                batch_count+=1\n",
    "\n",
    "                if self.gpu:\n",
    "                    source_data, source_labels = Variable(source_data.float().cuda()), Variable(source_labels.float().cuda())\n",
    "                    target_data, target_labels = Variable(target_data.float().cuda()), Variable(target_labels.float().cuda())\n",
    "\n",
    "                else:\n",
    "                    source_data, source_labels = Variable(source_data.float()), Variable(source_labels.float())\n",
    "                    target_data, target_labels = Variable(target_data.float()), Variable(target_labels.float())\n",
    "\n",
    "                for param in self.model['d'].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "                self.model['d'].zero_grad()\n",
    "\n",
    "                s_f = self.model['f'](source_data)      #generator \n",
    "                print(s_f.shape)\n",
    "                s_g = self.model['g'](s_f)\n",
    "                s_g_detach = s_g.detach()\n",
    "                s_d_g = self.model['d'](s_g_detach)\n",
    "                print(target_data.size())\n",
    "                t_data_3 = torch.cat((target_data,target_data,target_data),1)\n",
    "                t_f = self.model['f'](t_data_3)\n",
    "                t_g = self.model['g'](t_f)\n",
    "                t_g_detach = t_g.detach()\n",
    "                t_d_g = self.model['d'](t_g_detach)\n",
    "                #print(target_data.size())\n",
    "                t_d = self.model['d'](target_data)\n",
    "                \n",
    "                Discriminator_loss = self.discriminator_loss_function(s_d_g, t_d_g, t_d)\n",
    "                Discriminator_loss.backward()\n",
    "                self.discriminator_optimizer.step()\n",
    "\n",
    "                for param in self.model['g'].parameters():\n",
    "                      param.requires_grad = False\n",
    "\n",
    "                self.model['g'].zero_grad()\n",
    "\n",
    "                s_d_g = self.model['d'](s_g)\n",
    "                s_g_3 = torch.cat((s_g,s_g,s_g),1)\n",
    "                s_g_f = self.model['f'](s_g_3)\n",
    "\n",
    "                t_d_g = self.model['d'](t_g)\n",
    "\n",
    "                Generator_loss = self.generator_loss_function(s_f, s_g_f, s_d_g, target_data , t_g, t_d_g)\n",
    "                Generator_loss.backward()\n",
    "                self.generator_optimizer.step()\n",
    "\n",
    "                discriminator_run_loss+=Discriminator_loss.data.item()\n",
    "                generator_run_loss+=Generator_loss.data.item()\n",
    "    def delete_data(self):\n",
    "#         del self.source_data\n",
    "#         del self.target_data\n",
    "        del self.source_test_loader\n",
    "        del self.target_test_loader\n",
    "#         del source_test_set\n",
    "        del self.source_train_loader\n",
    "#         del source_train_set\n",
    "        del self.target_train_loader\n",
    "#         del target_train_set\n",
    "#         del target_test_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6q-Gq_1PCNaG"
   },
   "outputs": [],
   "source": [
    "dig=digits_transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V_1A3Ag7k5u"
   },
   "outputs": [],
   "source": [
    "dig.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "K5g4-2Px7_3-",
    "outputId": "30a8dcc3-6019-4808-ff96-2ca2b5194f65"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/torchvision/transforms/transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./SVHN/extra_32x32.mat\n",
      "Using downloaded and verified file: ./SVHN/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "dig.data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KSGBxxC8UOv"
   },
   "outputs": [],
   "source": [
    "dig.make_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIjGKP6_kVeP"
   },
   "outputs": [],
   "source": [
    "dig.make_loss_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "colab_type": "code",
    "id": "0-7aNN979J59",
    "outputId": "db052e80-5d37-4c74-ee6c-64fe53be527c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8f99b6e7b7e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-b1bb3ec67876>\u001b[0m in \u001b[0;36mmodel_train\u001b[0;34m(self, number_of_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mt_d_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mGenerator_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_g_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_d_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mt_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_d_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 \u001b[0mGenerator_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-b1bb3ec67876>\u001b[0m in \u001b[0;36mgenerator_loss\u001b[0;34m(s_f, s_g_f, s_d_g, t, t_g, t_d_g, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mloss_gan_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_d_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m#              + self.lossCrossEntropy(t_d_g, self.label_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mloss_feature_constancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_square_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_g_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mloss_target_identity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_square_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2156\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dig.model_train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dig.delete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZW8zOM6LOAJq"
   },
   "outputs": [],
   "source": [
    "qwe = torch.load('final_f.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HA20VUtbmsz_",
    "outputId": "b0d56e08-50d6-461d-c916-6f553a8ed69b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "for i in qwe:\n",
    "  if(i == 'state_dict'):\n",
    "    print(qwe[i]['classify.0.weight'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ef6XQ6xpmvCQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "digit_model_pytroch - V3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
